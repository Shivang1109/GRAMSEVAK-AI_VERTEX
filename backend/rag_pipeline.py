import os
import asyncio
from typing import List, Dict, Optional
import re
import json
from pathlib import Path
from intent_classifier import IntentClassifier
from safety_filter import SafetyFilter

# Initialize safety filter
safety_filter = SafetyFilter()

# Category-based index cache
_category_indices = {}

def load_category_index(category: str) -> List[Dict]:
    """Load category-specific index from file (cached)"""
    global _category_indices
    
    # Return from cache if already loaded
    if category in _category_indices:
        return _category_indices[category]
    
    # Load from file
    indices_dir = Path(__file__).parent / "indices"
    index_file = indices_dir / f"{category}_index.json"
    
    if not index_file.exists():
        print(f"‚ö†Ô∏è  Category index not found: {category}")
        return []
    
    try:
        with open(index_file, "r", encoding="utf-8") as f:
            entries = json.load(f)
            _category_indices[category] = entries
            print(f"üìÇ Loaded {len(entries)} entries for category: {category}")
            return entries
    except Exception as e:
        print(f"‚ùå Error loading category index {category}: {e}")
        return []

# Enhanced keyword matching with better flexibility
def simple_keyword_match(query: str, knowledge_base: List[Dict]) -> Dict:
    """Fast keyword-based matching with fuzzy search - returns structured data"""
    query_lower = query.lower()
    
    # Expanded keyword mappings (Hindi + English + Hinglish + Common phrases)
    keywords = {
        # Government Schemes
        "‡§ï‡§ø‡§∏‡§æ‡§®": ["pmkisan", "kisan", "farmer", "‡§ñ‡•á‡§§‡•Ä", "kheti", "agriculture"],
        "‡§â‡§ú‡•ç‡§ú‡•ç‡§µ‡§≤‡§æ": ["ujjwala", "gas", "lpg", "cylinder", "‡§∏‡§ø‡§≤‡•á‡§Ç‡§°‡§∞"],
        "‡§Ü‡§Ø‡•Å‡§∑‡•ç‡§Æ‡§æ‡§®": ["ayushman", "health", "hospital", "‡§á‡§≤‡§æ‡§ú", "ilaj", "treatment"],
        "‡§™‡•á‡§Ç‡§∂‡§®": ["pension", "atal", "retirement", "‡§¨‡•Å‡§¢‡§º‡§æ‡§™‡§æ"],
        "‡§®‡•å‡§ï‡§∞‡•Ä": ["mgnrega", "job", "work", "‡§ï‡§æ‡§Æ", "kaam", "employment", "‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞"],
        "‡§ò‡§∞": ["awas", "house", "home", "‡§Æ‡§ï‡§æ‡§®", "makaan", "housing"],
        "‡§≤‡•ã‡§®": ["mudra", "loan", "credit", "‡§ï‡§∞‡•ç‡§ú", "karj", "‡§â‡§ß‡§æ‡§∞"],
        "‡§∞‡§æ‡§∂‡§®": ["ration", "food", "‡§ñ‡§æ‡§®‡§æ", "‡§Ö‡§®‡§æ‡§ú", "grain"],
        "‡§∂‡•å‡§ö‡§æ‡§≤‡§Ø": ["toilet", "swachh", "sanitation", "latrine"],
        "‡§¨‡•à‡§Ç‡§ï": ["bank", "account", "‡§ñ‡§æ‡§§‡§æ", "jandhan"],
        
        # Agriculture
        "‡§´‡§∏‡§≤": ["crop", "‡§ñ‡•á‡§§‡•Ä", "farming", "‡§¨‡•Å‡§µ‡§æ‡§à", "sowing"],
        "‡§¨‡•Ä‡§ú": ["seed", "beej", "variety"],
        "‡§ñ‡§æ‡§¶": ["fertilizer", "urea", "npk", "manure"],
        "‡§ï‡•Ä‡§°‡§º‡§æ": ["pest", "insect", "disease", "‡§∞‡•ã‡§ó"],
        "‡§™‡§æ‡§®‡•Ä": ["water", "irrigation", "‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à", "drip"],
        "‡§Æ‡§Ç‡§°‡•Ä": ["mandi", "market", "price", "‡§≠‡§æ‡§µ", "rate"],
        
        # Health
        "‡§¨‡•Ä‡§Æ‡§æ‡§∞‡•Ä": ["disease", "illness", "sick", "‡§¨‡•Å‡§ñ‡§æ‡§∞", "fever"],
        "‡§¶‡§µ‡§æ": ["medicine", "tablet", "‡§ó‡•ã‡§≤‡•Ä", "treatment"],
        "‡§°‡•â‡§ï‡•ç‡§ü‡§∞": ["doctor", "hospital", "clinic", "‡§Ö‡§∏‡•ç‡§™‡§§‡§æ‡§≤"],
        "‡§ü‡•Ä‡§ï‡§æ": ["vaccine", "vaccination", "immunization"],
        
        # Education
        "‡§™‡§¢‡§º‡§æ‡§à": ["education", "study", "school", "‡§∏‡•ç‡§ï‡•Ç‡§≤"],
        "‡§õ‡§æ‡§§‡•ç‡§∞‡§µ‡•É‡§§‡•ç‡§§‡§ø": ["scholarship", "financial_aid"],
        "‡§®‡•å‡§ï‡§∞‡•Ä": ["job", "employment", "career"],
        
        # Financial
        "‡§™‡•à‡§∏‡§æ": ["money", "paisa", "rupee", "‡§∞‡•Å‡§™‡§Ø‡§æ"],
        "‡§¨‡§ö‡§§": ["savings", "save", "deposit"],
        "‡§¨‡•ç‡§Ø‡§æ‡§ú": ["interest", "rate"],
        
        # Common intent words
        "‡§ï‡•à‡§∏‡•á": ["how", "kaise", "process", "method"],
        "‡§ï‡•ç‡§Ø‡§æ": ["what", "kya", "information"],
        "‡§ï‡§ø‡§§‡§®‡§æ": ["how much", "kitna", "amount", "quantity"],
        "‡§ï‡§π‡§æ‡§Ç": ["where", "kahan", "location"],
        "‡§ï‡§¨": ["when", "kab", "time", "date"],
    }
    
    # Score each entry
    best_match = None
    best_score = 0
    
    for entry in knowledge_base:
        score = 0
        
        # Get all searchable text (support both old and new schema)
        entry_text = (
            entry.get("question_hi", "") + " " + 
            entry.get("summary", entry.get("answer_hi", "")) + " " +
            entry.get("title", entry.get("scheme", "")) + " " +
            " ".join(entry.get("tags", [])) + " " +
            entry.get("category", "") + " " +
            entry.get("subcategory", "") + " " +
            entry.get("eligibility", entry.get("eligibility_hi", ""))
        ).lower()
        
        # 1. Check direct keyword matches
        for hindi_word, eng_words in keywords.items():
            if hindi_word in query_lower:
                for eng_word in eng_words:
                    if eng_word in entry_text:
                        score += 10
        
        # 2. Check question variants (highest priority)
        for variant in entry.get("question_variants", []):
            variant_lower = variant.lower()
            # Exact match
            if variant_lower == query_lower:
                score += 50
            # Partial match
            elif variant_lower in query_lower or query_lower in variant_lower:
                score += 30
            # Word overlap
            else:
                query_words = set(query_lower.split())
                variant_words = set(variant_lower.split())
                overlap = len(query_words & variant_words)
                if overlap > 0:
                    score += overlap * 5
        
        # 3. Check tags
        for tag in entry.get("tags", []):
            if tag.lower() in query_lower:
                score += 15
        
        # 4. Check scheme/title name
        scheme_name = entry.get("title", entry.get("scheme", "")).lower()
        if scheme_name and scheme_name in query_lower:
            score += 20
        
        # 5. Word-by-word matching in question and answer
        query_words = query_lower.split()
        for word in query_words:
            if len(word) > 2:  # Skip very short words
                if word in entry_text:
                    score += 3
        
        # 6. Fuzzy matching for common misspellings
        fuzzy_matches = {
            "kisaan": "kisan",
            "kissan": "kisan",
            "yojna": "yojana",
            "yojana": "scheme",
            "paisa": "money",
            "paise": "money",
        }
        for wrong, correct in fuzzy_matches.items():
            if wrong in query_lower and correct in entry_text:
                score += 8
        
        if score > best_score:
            best_score = score
            best_match = entry
    
    # Return structured match if confidence is reasonable
    if best_match and best_score > 5:
        # Calculate confidence
        match_confidence = min(best_score / 50, 1.0)
        
        # Use confidence_weight from entry if available
        if best_match.get("confidence_weight"):
            entry_confidence = best_match["confidence_weight"]
            final_confidence = min((match_confidence + entry_confidence) / 2, 1.0)
        else:
            final_confidence = match_confidence
        
        # Determine retrieval method based on confidence
        if final_confidence >= 0.7:
            retrieval_method = "direct_match"
        elif final_confidence >= 0.4:
            retrieval_method = "semantic_match"
        else:
            retrieval_method = "semantic_match"  # Low confidence semantic
        
        # Extract structured fields from upgraded schema
        result = {
            "summary": best_match.get("summary", best_match.get("answer_hi", "")),
            "scheme_name": best_match.get("title", best_match.get("scheme", best_match.get("category", "‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø"))),
            "source": "keyword_match",
            "confidence": final_confidence,
            "retrieval_method": retrieval_method,
            "similarity_score": best_score / 100,  # Normalize to 0-1
            "last_updated": best_match.get("last_updated")  # Add freshness indicator
        }
        
        # Add optional fields if available
        if best_match.get("eligibility"):
            result["eligibility"] = best_match["eligibility"]
        
        if best_match.get("documents_required"):
            result["documents_required"] = best_match["documents_required"]
        
        if best_match.get("benefits"):
            result["benefits"] = best_match["benefits"]
        
        if best_match.get("official_link"):
            result["official_link"] = best_match["official_link"]
        
        return result
    
    return None

async def answer_query(query_text: str, knowledge_base: List[Dict], category_filter: Optional[str] = None, simulate_2g: bool = False) -> Dict:
    """
    Multi-stage retrieval with safety checks and confidence scoring:
    0. Safety filter check (crisis detection)
    1. Intent classification (category detection)
    2. Load category-specific index (if category detected)
    3. Fast keyword matching
    4. LLM-based answer if no good match (fallback)
    
    Args:
        query_text: User query
        knowledge_base: Full knowledge base (fallback only)
        category_filter: Optional category to filter KB (from intent classifier)
    """
    
    # STAGE 0: Safety Filter Check
    is_crisis, crisis_type, emergency_response = safety_filter.check_safety(query_text)
    
    if is_crisis:
        print(f"‚ö†Ô∏è  CRISIS DETECTED: {crisis_type} - Returning emergency response")
        # Return emergency response immediately, DO NOT use LLM
        return emergency_response
    
    # STAGE 1: Load category-specific index if category is specified
    search_kb = knowledge_base  # Default to full KB
    
    if category_filter and category_filter != 'general':
        # Try to load category-specific index
        category_entries = load_category_index(category_filter)
        
        if category_entries:
            search_kb = category_entries
            print(f"üîç Searching in category index: {category_filter} ({len(search_kb)} entries)")
        else:
            # Fallback to filtering full KB
            filtered_kb = [
                entry for entry in knowledge_base 
                if entry.get('category', '').lower() == category_filter.lower()
            ]
            search_kb = filtered_kb if filtered_kb else knowledge_base
            print(f"üîç Searching in filtered KB: {category_filter} ({len(search_kb)} entries)")
    else:
        print(f"üîç Searching in all categories ({len(search_kb)} entries)")
    
    # STAGE 2: Try keyword matching first
    keyword_result = simple_keyword_match(query_text, search_kb)
    
    # Check confidence threshold
    if keyword_result:
        confidence = keyword_result["confidence"]
        
        if confidence >= 0.3:
            # Good confidence - return result as is
            print(f"‚úÖ High confidence match: {confidence:.2f} (Method: {keyword_result['retrieval_method']})")
            return keyword_result
        else:
            # Low confidence - add disclaimer
            print(f"‚ö†Ô∏è  Low confidence match: {confidence:.2f} - Adding disclaimer")
            keyword_result["summary"] = (
                keyword_result["summary"] + 
                "\n\n‚ö†Ô∏è ‡§Ø‡§π ‡§â‡§§‡•ç‡§§‡§∞ ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§® ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§π‡•à, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ü‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§ï ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§¶‡•á‡§ñ‡•á‡§Ç‡•§"
            )
            keyword_result["low_confidence_warning"] = True
            keyword_result["retrieval_method"] = "semantic_match"  # Low confidence = semantic
            return keyword_result
    
    # STAGE 3: Use LLM for complex queries or low confidence matches
    # Skip LLM if in 2G simulation mode
    if simulate_2g:
        print("üêå 2G Mode: Skipping LLM, using best keyword match")
        if keyword_result:
            keyword_result["simulate_2g_mode"] = True
            keyword_result["summary"] = keyword_result["summary"][:200] + "..." if len(keyword_result["summary"]) > 200 else keyword_result["summary"]
            return keyword_result
        else:
            return {
                "summary": "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, 2G ‡§Æ‡•ã‡§° ‡§Æ‡•á‡§Ç ‡§Ø‡§π ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§¨‡•á‡§π‡§§‡§∞ ‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§™‡§∞ ‡§™‡•Å‡§®‡§É ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç‡•§",
                "scheme_name": "Unknown",
                "source": "fallback",
                "confidence": 0.0,
                "retrieval_method": "semantic_match",
                "similarity_score": 0.0,
                "simulate_2g_mode": True,
                "last_updated": None
            }
    
    try:
        llm_result = await llm_answer(query_text, search_kb)
        return llm_result
    except Exception as e:
        print(f"‚ö†Ô∏è  LLM Error: {e}")
        
        # Fallback: Return best keyword match with fallback flag
        if keyword_result:
            print("üì¥ Fallback mode: Using best keyword match")
            keyword_result["fallback_mode"] = True
            keyword_result["retrieval_method"] = "semantic_match"
            keyword_result["summary"] = (
                keyword_result["summary"] + 
                "\n\n‚ö†Ô∏è ‡§Ø‡§π ‡§â‡§§‡•ç‡§§‡§∞ ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§® ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§π‡•à, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ü‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§ï ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§¶‡•á‡§ñ‡•á‡§Ç‡•§"
            )
            return keyword_result
        
        # Ultimate fallback
        return {
            "summary": "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•Å‡§ù‡•á ‡§á‡§∏ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ 1800-180-1551 ‡§™‡§∞ ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§",
            "scheme_name": "Unknown",
            "source": "fallback",
            "confidence": 0.0,
            "retrieval_method": "semantic_match",
            "similarity_score": 0.0,
            "fallback_mode": True
        }

async def llm_answer(query_text: str, knowledge_base: List[Dict]) -> Dict:
    """Use Groq API for intelligent answers - returns structured data"""
    
    # Check if Groq API key is available
    groq_api_key = os.getenv("GROQ_API_KEY")
    
    if not groq_api_key:
        # Return a mock response for development
        return {
            "summary": "‡§Ø‡§π ‡§è‡§ï ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§â‡§§‡•ç‡§§‡§∞ ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ GROQ_API_KEY ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç‡•§",
            "scheme_name": "Test",
            "source": "mock",
            "confidence": 0.5,
            "retrieval_method": "rag_llm",
            "similarity_score": 0.5,
            "last_updated": None
        }
    
    try:
        from groq import Groq
        client = Groq(api_key=groq_api_key)
        
        # Build context from top schemes
        context_schemes = knowledge_base[:10]  # Use top 10 for context
        context = "\n".join([
            f"‡§µ‡§ø‡§∑‡§Ø: {s.get('scheme', s.get('category', '‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø'))}\n‡§™‡•ç‡§∞‡§∂‡•ç‡§®: {s.get('question_hi', '')}\n‡§â‡§§‡•ç‡§§‡§∞: {s.get('answer_hi', '')}"
            for s in context_schemes
        ])
        
        prompt = f"""‡§§‡•Å‡§Æ ‡§è‡§ï ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•ã‡•§ ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•ã‡•§

‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠:
{context}

‡§™‡•ç‡§∞‡§∂‡•ç‡§®: {query_text}

‡§â‡§§‡•ç‡§§‡§∞ (‡§ï‡•á‡§µ‡§≤ 3-4 ‡§µ‡§æ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç, ‡§∏‡§∞‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç):"""
        
        response = client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=150,
            temperature=0.1
        )
        
        answer_text = response.choices[0].message.content.strip()
        
        return {
            "summary": answer_text,
            "scheme_name": "AI Generated",
            "source": "groq_llm",
            "confidence": 0.8,
            "retrieval_method": "rag_llm",
            "similarity_score": 0.8,
            "last_updated": None  # LLM responses don't have fixed update date
        }
    
    except Exception as e:
        print(f"LLM Error: {e}")
        raise
